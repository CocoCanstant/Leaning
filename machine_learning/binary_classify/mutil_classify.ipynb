{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ouconstand/software/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/ouconstand/software/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/home/ouconstand/software/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words= 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 43,\n",
       " 10,\n",
       " 447,\n",
       " 5,\n",
       " 25,\n",
       " 207,\n",
       " 270,\n",
       " 5,\n",
       " 3095,\n",
       " 111,\n",
       " 16,\n",
       " 369,\n",
       " 186,\n",
       " 90,\n",
       " 67,\n",
       " 7,\n",
       " 89,\n",
       " 5,\n",
       " 19,\n",
       " 102,\n",
       " 6,\n",
       " 19,\n",
       " 124,\n",
       " 15,\n",
       " 90,\n",
       " 67,\n",
       " 84,\n",
       " 22,\n",
       " 482,\n",
       " 26,\n",
       " 7,\n",
       " 48,\n",
       " 4,\n",
       " 49,\n",
       " 8,\n",
       " 864,\n",
       " 39,\n",
       " 209,\n",
       " 154,\n",
       " 6,\n",
       " 151,\n",
       " 6,\n",
       " 83,\n",
       " 11,\n",
       " 15,\n",
       " 22,\n",
       " 155,\n",
       " 11,\n",
       " 15,\n",
       " 7,\n",
       " 48,\n",
       " 9,\n",
       " 4579,\n",
       " 1005,\n",
       " 504,\n",
       " 6,\n",
       " 258,\n",
       " 6,\n",
       " 272,\n",
       " 11,\n",
       " 15,\n",
       " 22,\n",
       " 134,\n",
       " 44,\n",
       " 11,\n",
       " 15,\n",
       " 16,\n",
       " 8,\n",
       " 197,\n",
       " 1245,\n",
       " 90,\n",
       " 67,\n",
       " 52,\n",
       " 29,\n",
       " 209,\n",
       " 30,\n",
       " 32,\n",
       " 132,\n",
       " 6,\n",
       " 109,\n",
       " 15,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[0]])\n",
    "decoded_newswire"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "向量化数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequence(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequence(train_data)\n",
    "x_test = vectorize_sequence(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimention=46):\n",
    "    results = np.zeros((len(labels), dimention))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1\n",
    "    return results\n",
    "\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16/16 [==============================] - 2s 70ms/step - loss: 3.0530 - accuracy: 0.3988 - val_loss: 1.6650 - val_accuracy: 0.6390\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 1.4386 - accuracy: 0.6983 - val_loss: 1.2627 - val_accuracy: 0.7350\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 1.0439 - accuracy: 0.7832 - val_loss: 1.1167 - val_accuracy: 0.7560\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.8290 - accuracy: 0.8274 - val_loss: 1.0021 - val_accuracy: 0.7850\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.6471 - accuracy: 0.8632 - val_loss: 0.9513 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 0.5173 - accuracy: 0.8922 - val_loss: 0.9029 - val_accuracy: 0.8140\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.4028 - accuracy: 0.9159 - val_loss: 0.9146 - val_accuracy: 0.8090\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.3494 - accuracy: 0.9233 - val_loss: 0.8760 - val_accuracy: 0.8200\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.2918 - accuracy: 0.9337 - val_loss: 0.8923 - val_accuracy: 0.8090\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.2362 - accuracy: 0.9467 - val_loss: 0.9284 - val_accuracy: 0.8050\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.1974 - accuracy: 0.9537 - val_loss: 1.0518 - val_accuracy: 0.7890\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.1712 - accuracy: 0.9588 - val_loss: 0.9084 - val_accuracy: 0.8230\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.1550 - accuracy: 0.9571 - val_loss: 0.9997 - val_accuracy: 0.7990\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.1513 - accuracy: 0.9533 - val_loss: 0.9809 - val_accuracy: 0.8180\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.1473 - accuracy: 0.9571 - val_loss: 0.9706 - val_accuracy: 0.8190\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.1247 - accuracy: 0.9565 - val_loss: 1.0352 - val_accuracy: 0.8060\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.1173 - accuracy: 0.9598 - val_loss: 1.0218 - val_accuracy: 0.8200\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.1149 - accuracy: 0.9597 - val_loss: 1.0648 - val_accuracy: 0.8020\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.1009 - accuracy: 0.9649 - val_loss: 1.0854 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0954 - accuracy: 0.9634 - val_loss: 1.0765 - val_accuracy: 0.8180\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train, partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eace1a3d2d18dcb98353cfeb529f20792ec64dcc10ba0bdd358326e3f660811b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
