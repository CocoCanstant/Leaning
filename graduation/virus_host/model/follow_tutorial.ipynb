{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(2)\n",
    "a = torch.rand(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6147, 0.3810, 0.6371],\n",
       "        [0.4745, 0.7136, 0.6190],\n",
       "        [0.4425, 0.0958, 0.6142]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1.],\n",
       "        [0., 1., 1.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjacent matrix\n",
    "a[a>0.5] = 1\n",
    "a[a<0.5] = 0\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 1.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 0., 0.],\n",
       "        [0., 2., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# degree matrix\n",
    "def Degree_matrix(a):\n",
    "    return torch.diag(a.sum(dim=1))\n",
    "d = Degree_matrix(a)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  0., -1.],\n",
       "        [ 0.,  1., -1.],\n",
       "        [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# laplacian matrix\n",
    "# L = Degree matrix - Adjacent matrix\n",
    "def laplacian(a):\n",
    "    return Degree_matrix(a)-a\n",
    "l = laplacian(a)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def calc_degree_matrix_norm(a):\n",
    "    return torch.diag(torch.pow(a.sum(dim=-1),-0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7071, 0.0000, 0.0000],\n",
       "        [0.0000, 0.7071, 0.0000],\n",
       "        [0.0000, 0.0000, 1.0000]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_degree_matrix_norm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L_norm = I - (D^-0.5 * A * D^-0.5)\n",
    "def create_graph_lapl_norm(a):\n",
    " size = a.shape[-1]\n",
    " D_norm = calc_degree_matrix_norm(a)\n",
    " L_norm = torch.ones(size) - (D_norm @ a @ D_norm )\n",
    " return L_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 1.0000, 0.2929],\n",
       "        [1.0000, 0.5000, 0.2929],\n",
       "        [1.0000, 1.0000, 0.0000]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_graph_lapl_norm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom grade is 8\n",
      "Jerry grade is 7\n"
     ]
    }
   ],
   "source": [
    "class Student_Grade: \n",
    "    def __init__(self, name, grade):  \n",
    "        self.name = name\n",
    "        self.grade = grade\n",
    "\n",
    "    def print_grade(self):\n",
    "        print(\"%s grade is %s\" % (self.name,self.grade))\n",
    "\n",
    "s1 = Student_Grade(\"Tom\", 8)  # 创建对象s1，实例化直接传入参数\n",
    "s2 = Student_Grade(\"Jerry\", 7)  # 创建对象s2\n",
    "\n",
    "s1.print_grade()\n",
    "s2.print_grade()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-eab42696f2a1>, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-eab42696f2a1>\"\u001b[0;36m, line \u001b[0;32m25\u001b[0m\n\u001b[0;31m    super().__init__()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def device_as(x,y):\n",
    "  return x.to(y.device)\n",
    "\n",
    "# tensor operations now support batched inputs\n",
    "def calc_degree_matrix_norm(a):\n",
    "  return torch.diag_embed(torch.pow(a.sum(dim=-1),-0.5))\n",
    "\n",
    "def create_graph_lapl_norm(a):\n",
    "  size = a.shape[-1]\n",
    "  a +=  device_as(torch.eye(size),a)\n",
    "  D_norm = calc_degree_matrix_norm(a)\n",
    "  L_norm = torch.bmm( torch.bmm(D_norm, a) , D_norm )\n",
    "  return L_norm\n",
    "\n",
    "class GCN_AISUMMER(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "    super().__init__()\n",
    "    self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "\n",
    "    def forward(self, X, A):\n",
    "        \"\"\"\n",
    "        A: adjecency matrix\n",
    "        X: graph signal\n",
    "        \"\"\"\n",
    "        L = create_graph_lapl_norm(A)\n",
    "        x = self.linear(X)\n",
    "        return torch.bmm(L, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "\n",
    "data = 'hello world'\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = 'abcdefghijklmnopqrstuvwxyz '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'b': 1,\n",
       " 'c': 2,\n",
       " 'd': 3,\n",
       " 'e': 4,\n",
       " 'f': 5,\n",
       " 'g': 6,\n",
       " 'h': 7,\n",
       " 'i': 8,\n",
       " 'j': 9,\n",
       " 'k': 10,\n",
       " 'l': 11,\n",
       " 'm': 12,\n",
       " 'n': 13,\n",
       " 'o': 14,\n",
       " 'p': 15,\n",
       " 'q': 16,\n",
       " 'r': 17,\n",
       " 's': 18,\n",
       " 't': 19,\n",
       " 'u': 20,\n",
       " 'v': 21,\n",
       " 'w': 22,\n",
       " 'x': 23,\n",
       " 'y': 24,\n",
       " 'z': 25,\n",
       " ' ': 26}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "char_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_encoded = [char_to_int[char] for char in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 4, 11, 11, 14, 26, 22, 14, 17, 11, 3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "onehot_encoded = list()\n",
    "\n",
    "for value in integer_encoded:\n",
    " letter = [0 for _ in range(len(alphabet))]\n",
    " letter[value] = 1\n",
    " onehot_encoded.append(letter)\n",
    "print(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted = int_to_char[argmax(onehot_encoded[0])]\n",
    "inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eace1a3d2d18dcb98353cfeb529f20792ec64dcc10ba0bdd358326e3f660811b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
